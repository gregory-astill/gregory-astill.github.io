---
layout: page
title: About Me
subtitle: Economist, Researcher, Data Scientist
---
I love researching, analyzing data, and making beautiful figures. 

- To research I read primary source documents including books, journal articles, Federal legislation, government reports, and digital databases. 
- To analyze data I use classical statistics and regressions, machine learning algorithms, and other methods primarily in R, Stata, and Python.
- To make beautiful figures I use ggplot and usmap in Rmarkdown for R, matplotlib in Jupyter Notebooks for Python, and ol' reliable Excel.

### My Career & My Approach

I graduated from Brigham Young University with a B.A. in International Relations in 2011 and from Washington State University with a Ph.D. in Economics in 2016. Since 2016 I have been employed by the Economic Research Service in the U.S. Department of Agriculture. My approach to research, data analysis, and life is captured in the question, "<i>How would I know if I were wrong?</i>". The scientific method and Karl Popper's criterion of falsifiability are built on a similar line of reasoning.

When it comes to research, I carefully assess the quality of sources and what information exactly they convey. When it comes to data analysis, I code defensively, use principles of reproducibility, and perform regular tests to confirm that the results are not contaminated with errors. 

When interpreting the results of statistical analyses, I am careful to remember the true meaning of p-values, the potential for biased estimates if certain assumptions about the data generating process do not hold, and the importance of evaluating the economic significance of parameter estimates. 

When using machine learning algorithms, I approach the data thoughtfully--identifying what the data actually measure, what the causal relationships between variables might be, and what missing data might be a source of error-- and I am meticulous about maintaining the integrity of the training and testing data sets. 

My CV can be downloaded here.
